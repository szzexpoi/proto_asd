{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import operator\n",
    "from scipy.stats import pearsonr,spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './gradcam_result_single_proto//'\n",
    "img_dir = '../autism_photo_taking/'\n",
    "save_dir = './visualization/visualization_cnn'\n",
    "idx2category = {0:'indoor',1:'outdoor',2:'people'}\n",
    "\n",
    "for category in ['ASD','Ctrl']:\n",
    "    if not os.path.exists(os.path.join(save_dir,category)):\n",
    "        os.mkdir(os.path.join(save_dir,category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay for consistency\n",
    "def overlay_heatmap(img,att,cmap=plt.cm.jet):\n",
    "    gamma = 1.0\n",
    "    att[att<0.5] = 0.01\n",
    "    att = cv2.blur(att,(10,10)) # originally 35\n",
    "    colorized = cmap(np.uint8(att*255))\n",
    "    alpha = 0.5\n",
    "#     alpha = np.repeat((att[:,:,np.newaxis]**gamma+1)/2,3,axis=2)\n",
    "    overlaid = np.uint8(img*(1-alpha)+colorized[:,:,2::-1]*255*alpha)\n",
    "    return overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the gradient-based explanation maps (single)\n",
    "files = glob(os.path.join(data_dir,'*.npy'))\n",
    "for cur_file in files:\n",
    "    cur_id = os.path.basename(cur_file)[:-4]\n",
    "    cur_data = np.load(os.path.join(cur_file),allow_pickle=True).item()\n",
    "    cur_label = cur_data['label']\n",
    "    if cur_label == 1:\n",
    "        cur_label = 'ASD'\n",
    "    else:\n",
    "        cur_label = 'Ctrl'\n",
    "    \n",
    "    if not os.path.exists(os.path.join(save_dir,cur_label)):\n",
    "        os.mkdir(os.path.join(save_dir,cur_label))\n",
    "        \n",
    "    cur_category = idx2category[cur_data['category']]\n",
    "    if not os.path.exists(os.path.join(save_dir,cur_label,cur_category)):\n",
    "        os.mkdir(os.path.join(save_dir,cur_label,cur_category))\n",
    "    cam_map = cur_data['pixel_importance']\n",
    "    cam_map = cv2.resize(cam_map,(224,224))\n",
    "    if cam_map.max()>0:\n",
    "        cam_map /= cam_map.max()\n",
    "    else:\n",
    "        continue\n",
    "    cur_img = cv2.imread(os.path.join(img_dir,cur_label,cur_id+'.jpg'))\n",
    "    cur_map = overlay_heatmap(cur_img,cam_map)\n",
    "    cv2.imwrite(os.path.join(save_dir,cur_label,cur_category,cur_id+'.jpg'),cur_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the importance of different prototypes (single-image)\n",
    "overall_proto = dict()\n",
    "num_proto = 20 # number of asd and ctrl prototypes\n",
    "for label in ['asd','ctrl']:\n",
    "    overall_proto[label] = dict()\n",
    "    for proto_id in range(num_proto):\n",
    "        overall_proto[label][proto_id] = []\n",
    "\n",
    "files = glob(os.path.join(data_dir,'*.npy'))\n",
    "for cur_file in files:\n",
    "    cur_id = os.path.basename(cur_file)[:-4]\n",
    "    cur_data = np.load(os.path.join(cur_file),allow_pickle=True).item()\n",
    "    cur_label = 'asd' if cur_data['label'] else 'ctrl'\n",
    "    \n",
    "    cur_proto = cur_data['cluster_assignment']\n",
    "    cur_importance = cur_data['acc']\n",
    "    overall_proto[cur_label][cur_proto].append(cur_importance)\n",
    "\n",
    "# overall importance on different prototypes\n",
    "for label in ['asd','ctrl']:\n",
    "    print('Overall importance on top-8 prototypes for group %s' %label)\n",
    "    res = []\n",
    "    var = []\n",
    "#     res = [np.sum(overall_proto[label][cur]) for cur in range(num_proto)]\n",
    "    for cur in range(num_proto):\n",
    "        if len(overall_proto[label][cur]) == 0:\n",
    "            res.append(0)\n",
    "            var.append(0)\n",
    "        else:\n",
    "            res.append(np.mean(overall_proto[label][cur]))\n",
    "            var.append(np.std(overall_proto[label][cur]))\n",
    "    var = [cur/np.sum(res) for cur in var]\n",
    "    res = [cur/np.sum(res) for cur in res]\n",
    "    top_idx = np.argsort(res)[::-1]\n",
    "    for i in range(20):\n",
    "        print('%d: %.3f %.3f' %(top_idx[i],res[top_idx[i]], var[top_idx[i]]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
